"use strict";(globalThis.webpackChunkuip_urban_intelligence_platform_docs=globalThis.webpackChunkuip_urban_intelligence_platform_docs||[]).push([[5774],{3753:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>a,contentTitle:()=>c,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>d});var i=t(8669),s=t(4848),l=t(8453);const r={slug:"ai-accident-detection",title:"\ud83d\udea8 Ph\xe1t hi\u1ec7n Tai n\u1ea1n Giao th\xf4ng v\u1edbi AI",authors:["nguyennhatquang","nguyenviethoang"],tags:["uip","ai","yolox","accident-detection","computer-vision"]},c="YOLOX v\xe0 Ph\xe1t hi\u1ec7n Tai n\u1ea1n Giao th\xf4ng Real-time \ud83e\udd16",a={authorsImageUrls:[void 0,void 0]},d=[{value:"\ud83c\udfaf V\u1ea5n \u0111\u1ec1 c\u1ea7n gi\u1ea3i quy\u1ebft",id:"-v\u1ea5n-\u0111\u1ec1-c\u1ea7n-gi\u1ea3i-quy\u1ebft",level:2},{value:"\ud83e\udde0 L\u1ef1a ch\u1ecdn Model: T\u1ea1i sao YOLOX?",id:"-l\u1ef1a-ch\u1ecdn-model-t\u1ea1i-sao-yolox",level:2},{value:"So s\xe1nh c\xe1c model",id:"so-s\xe1nh-c\xe1c-model",level:3},{value:"\ud83c\udfd7\ufe0f Ki\u1ebfn tr\xfac h\u1ec7 th\u1ed1ng",id:"\ufe0f-ki\u1ebfn-tr\xfac-h\u1ec7-th\u1ed1ng",level:2},{value:"\ud83d\udcbb Implementation",id:"-implementation",level:2},{value:"1. Model Loading",id:"1-model-loading",level:3},{value:"2. Inference Pipeline",id:"2-inference-pipeline",level:3},{value:"3. Alert Dispatch",id:"3-alert-dispatch",level:3},{value:"\ud83d\udcca Training Data",id:"-training-data",level:2},{value:"Dataset Composition",id:"dataset-composition",level:3},{value:"Data Augmentation",id:"data-augmentation",level:3},{value:"\ud83d\udcc8 Performance Results",id:"-performance-results",level:2},{value:"Accuracy Metrics",id:"accuracy-metrics",level:3},{value:"Speed Metrics",id:"speed-metrics",level:3},{value:"\ud83d\ude80 Deployment",id:"-deployment",level:2},{value:"GPU Optimization",id:"gpu-optimization",level:3},{value:"Batch Processing",id:"batch-processing",level:3},{value:"\ud83d\udcca Real-world Results",id:"-real-world-results",level:2},{value:"\ud83c\udf93 Lessons Learned",id:"-lessons-learned",level:2},{value:"\ud83d\udd1c Future Work",id:"-future-work",level:2}];function o(e){const n={a:"a",code:"code",em:"em",h2:"h2",h3:"h3",hr:"hr",input:"input",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,l.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)(n.p,{children:["M\u1ed9t trong nh\u1eefng t\xednh n\u0103ng quan tr\u1ecdng nh\u1ea5t c\u1ee7a UIP l\xe0 kh\u1ea3 n\u0103ng ",(0,s.jsx)(n.strong,{children:"ph\xe1t hi\u1ec7n tai n\u1ea1n giao th\xf4ng t\u1ef1 \u0111\u1ed9ng"})," trong v\xf2ng v\xe0i gi\xe2y. B\xe0i vi\u1ebft n\xe0y chia s\u1ebb c\xe1ch ch\xfang t\xf4i x\xe2y d\u1ef1ng h\u1ec7 th\u1ed1ng n\xe0y."]}),"\n",(0,s.jsx)(n.h2,{id:"-v\u1ea5n-\u0111\u1ec1-c\u1ea7n-gi\u1ea3i-quy\u1ebft",children:"\ud83c\udfaf V\u1ea5n \u0111\u1ec1 c\u1ea7n gi\u1ea3i quy\u1ebft"}),"\n",(0,s.jsx)(n.p,{children:"T\u1ea1i TP.HCM, m\u1ed7i n\u0103m c\xf3 h\xe0ng ngh\xecn v\u1ee5 tai n\u1ea1n giao th\xf4ng. Th\u1eddi gian ph\u1ea3n \u1ee9ng nhanh l\xe0 y\u1ebfu t\u1ed1 quy\u1ebft \u0111\u1ecbnh \u0111\u1ec3:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"\ud83d\ude91 C\u1ee9u s\u1ed1ng n\u1ea1n nh\xe2n"}),"\n",(0,s.jsx)(n.li,{children:"\ud83d\ude97 Gi\u1ea3m \xf9n t\u1eafc giao th\xf4ng k\xe9o d\xe0i"}),"\n",(0,s.jsx)(n.li,{children:"\ud83d\udcca Thu th\u1eadp d\u1eef li\u1ec7u ch\xednh x\xe1c"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"M\u1ee5c ti\xeau:"})," Ph\xe1t hi\u1ec7n tai n\u1ea1n trong ",(0,s.jsx)(n.strong,{children:"< 3 gi\xe2y"})," v\u1edbi \u0111\u1ed9 ch\xednh x\xe1c ",(0,s.jsx)(n.strong,{children:"> 90%"})]}),"\n",(0,s.jsx)(n.h2,{id:"-l\u1ef1a-ch\u1ecdn-model-t\u1ea1i-sao-yolox",children:"\ud83e\udde0 L\u1ef1a ch\u1ecdn Model: T\u1ea1i sao YOLOX?"}),"\n",(0,s.jsx)(n.h3,{id:"so-s\xe1nh-c\xe1c-model",children:"So s\xe1nh c\xe1c model"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Model"}),(0,s.jsx)(n.th,{children:"mAP"}),(0,s.jsx)(n.th,{children:"Speed (FPS)"}),(0,s.jsx)(n.th,{children:"Size"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"YOLOv5"}),(0,s.jsx)(n.td,{children:"50.7%"}),(0,s.jsx)(n.td,{children:"140"}),(0,s.jsx)(n.td,{children:"27MB"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"YOLOv7"}),(0,s.jsx)(n.td,{children:"51.2%"}),(0,s.jsx)(n.td,{children:"120"}),(0,s.jsx)(n.td,{children:"37MB"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"YOLOX"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"51.1%"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"155"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"25MB"})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"YOLOR"}),(0,s.jsx)(n.td,{children:"52.0%"}),(0,s.jsx)(n.td,{children:"80"}),(0,s.jsx)(n.td,{children:"45MB"})]})]})]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"YOLOX"})," l\xe0 l\u1ef1a ch\u1ecdn t\u1ed1i \u01b0u v\xec:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"\u2705 Anchor-free design - \u0111\u01a1n gi\u1ea3n h\u01a1n"}),"\n",(0,s.jsx)(n.li,{children:"\u2705 Decoupled head - train nhanh h\u01a1n"}),"\n",(0,s.jsx)(n.li,{children:"\u2705 SimOTA label assignment - ch\xednh x\xe1c h\u01a1n"}),"\n",(0,s.jsx)(n.li,{children:"\u2705 Strong augmentation - robust h\u01a1n"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"\ufe0f-ki\u1ebfn-tr\xfac-h\u1ec7-th\u1ed1ng",children:"\ud83c\udfd7\ufe0f Ki\u1ebfn tr\xfac h\u1ec7 th\u1ed1ng"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Camera    \u2502\u2500\u2500\u2500\u2500\u25b6\u2502   Image     \u2502\u2500\u2500\u2500\u2500\u25b6\u2502   YOLOX     \u2502\n\u2502   Stream    \u2502     \u2502   Buffer    \u2502     \u2502   Model     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                               \u2502\n                                               \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Alert     \u2502\u25c0\u2500\u2500\u2500\u2500\u2502   Post      \u2502\u25c0\u2500\u2500\u2500\u2500\u2502  Detection  \u2502\n\u2502   System    \u2502     \u2502   Process   \u2502     \u2502   Results   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,s.jsx)(n.h2,{id:"-implementation",children:"\ud83d\udcbb Implementation"}),"\n",(0,s.jsx)(n.h3,{id:"1-model-loading",children:"1. Model Loading"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import torch\nfrom yolox.exp import get_exp\nfrom yolox.utils import postprocess\n\nclass AccidentDetector:\n    def __init__(self, model_path: str, device: str = "cuda"):\n        self.device = device\n        self.exp = get_exp("yolox_s")\n        self.model = self.exp.get_model()\n        \n        # Load pretrained weights\n        checkpoint = torch.load(model_path, map_location=device)\n        self.model.load_state_dict(checkpoint["model"])\n        self.model.to(device)\n        self.model.eval()\n        \n        # Accident-related classes\n        self.accident_classes = [\n            "car_crash",\n            "motorcycle_fallen",\n            "person_injured",\n            "vehicle_damage"\n        ]\n'})}),"\n",(0,s.jsx)(n.h3,{id:"2-inference-pipeline",children:"2. Inference Pipeline"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'async def detect_accidents(self, images: List[np.ndarray]) -> List[Detection]:\n    """Process batch of images for accident detection"""\n    detections = []\n    \n    # Preprocess\n    batch = self.preprocess_batch(images)\n    \n    with torch.no_grad():\n        # Forward pass\n        outputs = self.model(batch)\n        \n        # Post-process\n        outputs = postprocess(\n            outputs,\n            num_classes=len(self.classes),\n            conf_thre=0.7,\n            nms_thre=0.45\n        )\n    \n    for i, output in enumerate(outputs):\n        if output is None:\n            continue\n            \n        for det in output:\n            cls = int(det[6])\n            conf = float(det[4] * det[5])\n            \n            if self.classes[cls] in self.accident_classes:\n                detections.append(Detection(\n                    image_id=i,\n                    class_name=self.classes[cls],\n                    confidence=conf,\n                    bbox=det[:4].tolist(),\n                    timestamp=datetime.now()\n                ))\n    \n    return detections\n'})}),"\n",(0,s.jsx)(n.h3,{id:"3-alert-dispatch",children:"3. Alert Dispatch"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'async def dispatch_alert(self, detection: Detection, camera: Camera):\n    """Send accident alert through multiple channels"""\n    \n    alert = AccidentAlert(\n        camera_id=camera.id,\n        location=camera.location,\n        severity=self.calculate_severity(detection),\n        confidence=detection.confidence,\n        timestamp=detection.timestamp,\n        image_url=await self.capture_snapshot(camera)\n    )\n    \n    # Multi-channel dispatch\n    await asyncio.gather(\n        self.send_websocket_alert(alert),\n        self.send_email_alert(alert),\n        self.send_sms_alert(alert),\n        self.store_in_database(alert),\n        self.publish_ngsi_ld_entity(alert)\n    )\n'})}),"\n",(0,s.jsx)(n.h2,{id:"-training-data",children:"\ud83d\udcca Training Data"}),"\n",(0,s.jsx)(n.h3,{id:"dataset-composition",children:"Dataset Composition"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Category"}),(0,s.jsx)(n.th,{children:"Images"}),(0,s.jsx)(n.th,{children:"Annotations"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Car crashes"}),(0,s.jsx)(n.td,{children:"5,000"}),(0,s.jsx)(n.td,{children:"12,000"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Motorcycle falls"}),(0,s.jsx)(n.td,{children:"3,500"}),(0,s.jsx)(n.td,{children:"8,000"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Pedestrian incidents"}),(0,s.jsx)(n.td,{children:"2,000"}),(0,s.jsx)(n.td,{children:"4,500"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Multi-vehicle"}),(0,s.jsx)(n.td,{children:"1,500"}),(0,s.jsx)(n.td,{children:"5,000"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Total"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"12,000"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"29,500"})})]})]})]}),"\n",(0,s.jsx)(n.h3,{id:"data-augmentation",children:"Data Augmentation"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"from albumentations import (\n    Compose, RandomBrightnessContrast,\n    RandomRain, RandomFog, RandomSunFlare,\n    HorizontalFlip, RandomScale\n)\n\ntransform = Compose([\n    RandomBrightnessContrast(p=0.5),\n    RandomRain(p=0.3),           # M\u01b0a\n    RandomFog(p=0.2),            # S\u01b0\u01a1ng m\xf9\n    RandomSunFlare(p=0.2),       # Ch\xf3i s\xe1ng\n    HorizontalFlip(p=0.5),\n    RandomScale(scale_limit=0.2, p=0.5)\n])\n"})}),"\n",(0,s.jsx)(n.h2,{id:"-performance-results",children:"\ud83d\udcc8 Performance Results"}),"\n",(0,s.jsx)(n.h3,{id:"accuracy-metrics",children:"Accuracy Metrics"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Metric"}),(0,s.jsx)(n.th,{children:"Value"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"mAP@0.5"}),(0,s.jsx)(n.td,{children:"91.2%"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"mAP@0.5:0.95"}),(0,s.jsx)(n.td,{children:"72.8%"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Precision"}),(0,s.jsx)(n.td,{children:"89.5%"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Recall"}),(0,s.jsx)(n.td,{children:"93.1%"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"F1-Score"}),(0,s.jsx)(n.td,{children:"91.3%"})]})]})]}),"\n",(0,s.jsx)(n.h3,{id:"speed-metrics",children:"Speed Metrics"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Hardware"}),(0,s.jsx)(n.th,{children:"FPS"}),(0,s.jsx)(n.th,{children:"Latency"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"RTX 3080"}),(0,s.jsx)(n.td,{children:"155"}),(0,s.jsx)(n.td,{children:"6.5ms"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"RTX 3060"}),(0,s.jsx)(n.td,{children:"120"}),(0,s.jsx)(n.td,{children:"8.3ms"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"T4 (Cloud)"}),(0,s.jsx)(n.td,{children:"95"}),(0,s.jsx)(n.td,{children:"10.5ms"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"CPU (i7-12700)"}),(0,s.jsx)(n.td,{children:"15"}),(0,s.jsx)(n.td,{children:"66ms"})]})]})]}),"\n",(0,s.jsx)(n.h2,{id:"-deployment",children:"\ud83d\ude80 Deployment"}),"\n",(0,s.jsx)(n.h3,{id:"gpu-optimization",children:"GPU Optimization"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# TensorRT optimization\nimport tensorrt as trt\n\ndef optimize_for_tensorrt(model_path: str, output_path: str):\n    """Convert ONNX model to TensorRT"""\n    logger = trt.Logger(trt.Logger.INFO)\n    builder = trt.Builder(logger)\n    \n    config = builder.create_builder_config()\n    config.set_flag(trt.BuilderFlag.FP16)  # Half precision\n    config.max_workspace_size = 1 << 30    # 1GB\n    \n    network = builder.create_network(\n        1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n    )\n    \n    parser = trt.OnnxParser(network, logger)\n    with open(model_path, \'rb\') as f:\n        parser.parse(f.read())\n    \n    engine = builder.build_serialized_network(network, config)\n    \n    with open(output_path, \'wb\') as f:\n        f.write(engine)\n'})}),"\n",(0,s.jsx)(n.h3,{id:"batch-processing",children:"Batch Processing"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'async def process_camera_batch(cameras: List[Camera], batch_size: int = 32):\n    """Process cameras in batches for efficiency"""\n    \n    for i in range(0, len(cameras), batch_size):\n        batch = cameras[i:i + batch_size]\n        \n        # Fetch images concurrently\n        images = await asyncio.gather(*[\n            fetch_camera_image(cam) for cam in batch\n        ])\n        \n        # Batch inference\n        detections = await detector.detect_accidents(images)\n        \n        # Process detections\n        for detection in detections:\n            if detection.is_accident:\n                await dispatch_alert(detection, batch[detection.image_id])\n'})}),"\n",(0,s.jsx)(n.h2,{id:"-real-world-results",children:"\ud83d\udcca Real-world Results"}),"\n",(0,s.jsx)(n.p,{children:"Sau 3 th\xe1ng tri\u1ec3n khai th\u1eed nghi\u1ec7m:"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Metric"}),(0,s.jsx)(n.th,{children:"Value"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Tai n\u1ea1n ph\xe1t hi\u1ec7n"}),(0,s.jsx)(n.td,{children:"127 v\u1ee5"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Th\u1eddi gian ph\xe1t hi\u1ec7n TB"}),(0,s.jsx)(n.td,{children:"2.3 gi\xe2y"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"False positives"}),(0,s.jsx)(n.td,{children:"8 (6.3%)"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Th\u1eddi gian ph\u1ea3n \u1ee9ng gi\u1ea3m"}),(0,s.jsx)(n.td,{children:"45%"})]})]})]}),"\n",(0,s.jsx)(n.h2,{id:"-lessons-learned",children:"\ud83c\udf93 Lessons Learned"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Lighting matters"})," - Augmentation v\u1edbi c\xe1c \u0111i\u1ec1u ki\u1ec7n \xe1nh s\xe1ng kh\xe1c nhau r\u1ea5t quan tr\u1ecdng"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Context helps"})," - K\u1ebft h\u1ee3p th\xf4ng tin camera position c\u1ea3i thi\u1ec7n accuracy"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Edge cases"})," - Xe m\xe1y nh\u1ecf kh\xf3 ph\xe1t hi\u1ec7n h\u01a1n \xf4 t\xf4"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"False positives"})," - C\u1ea7n filtering th\xf4ng minh \u0111\u1ec3 gi\u1ea3m false alarms"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"-future-work",children:"\ud83d\udd1c Future Work"}),"\n",(0,s.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Multi-camera tracking"]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Severity estimation"]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Incident type classification"]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Integration v\u1edbi emergency services"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"B\u1ea1n mu\u1ed1n \u0111\xf3ng g\xf3p?"})," Xem ",(0,s.jsx)(n.a,{href:"/docs/guides/contributing",children:"Contributing Guide"})," \u0111\u1ec3 b\u1eaft \u0111\u1ea7u!"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.em,{children:"Nguy\u1ec5n Nh\u1eadt Quang & Nguy\u1ec5n Vi\u1ec7t Ho\xe0ng - UIP Team"})})]})}function h(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(o,{...e})}):o(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>c});var i=t(6540);const s={},l=i.createContext(s);function r(e){const n=i.useContext(l);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),i.createElement(l.Provider,{value:n},e.children)}},8669:e=>{e.exports=JSON.parse('{"permalink":"/tes/vi/blog/ai-accident-detection","editUrl":"https://github.com/NguyenNhatquang522004/UIP-Urban_Intelligence_Platform/tree/main/apps/traffic-web-app/frontend/docs/blog/2024-05-15-ai-accident-detection.md","source":"@site/blog/2024-05-15-ai-accident-detection.md","title":"\ud83d\udea8 Ph\xe1t hi\u1ec7n Tai n\u1ea1n Giao th\xf4ng v\u1edbi AI","description":"\x3c!--","date":"2024-05-15T00:00:00.000Z","tags":[{"inline":false,"label":"UIP","permalink":"/tes/vi/blog/tags/uip","description":"UIP - Urban Intelligence Platform core content"},{"inline":false,"label":"AI","permalink":"/tes/vi/blog/tags/ai","description":"Artificial Intelligence"},{"inline":false,"label":"YOLOX","permalink":"/tes/vi/blog/tags/yolox","description":"YOLOX object detection model"},{"inline":false,"label":"Accident Detection","permalink":"/tes/vi/blog/tags/accident-detection","description":"AI-powered accident detection"},{"inline":false,"label":"Computer Vision","permalink":"/tes/vi/blog/tags/computer-vision","description":"Computer vision and image processing"}],"readingTime":3.88,"hasTruncateMarker":true,"authors":[{"name":"Nguy\u1ec5n Nh\u1eadt Quang","title":"Lead Developer & System Architect","url":"https://github.com/NguyenNhatquang522004","page":{"permalink":"/tes/vi/blog/authors/nguyennhatquang"},"socials":{"github":"https://github.com/NguyenNhatquang522004","email":"mailto:nguyennhatquang522004@gmail.com"},"imageURL":"https://github.com/NguyenNhatquang522004.png","key":"nguyennhatquang"},{"name":"Nguy\u1ec5n Vi\u1ec7t Ho\xe0ng","title":"Full-Stack Developer","url":"https://github.com/JamesNguyen106","page":{"permalink":"/tes/vi/blog/authors/nguyenviethoang"},"socials":{"github":"https://github.com/JamesNguyen106","email":"mailto:viethoang01062004nt@gmail.com"},"imageURL":"https://github.com/JamesNguyen106.png","key":"nguyenviethoang"}],"frontMatter":{"slug":"ai-accident-detection","title":"\ud83d\udea8 Ph\xe1t hi\u1ec7n Tai n\u1ea1n Giao th\xf4ng v\u1edbi AI","authors":["nguyennhatquang","nguyenviethoang"],"tags":["uip","ai","yolox","accident-detection","computer-vision"]},"unlisted":false,"prevItem":{"title":"\ud83d\udcf1 X\xe2y d\u1ef1ng H\u1ec7 th\u1ed1ng B\xe1o c\xe1o C\xf4ng d\xe2n","permalink":"/tes/vi/blog/citizen-reporting-system"},"nextItem":{"title":"\ud83c\udfa8 Ki\u1ebfn tr\xfac Frontend c\u1ee7a UIP v\u1edbi React 18","permalink":"/tes/vi/blog/frontend-architecture"}}')}}]);